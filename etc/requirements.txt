absl-py @ file:///D:/bld/absl-py_1606235847480/work
astor @ file:///home/conda/feedstock_root/build_artifacts/astor_1593610464257/work
backcall==0.2.0
cached-property==1.5.1
certifi==2020.12.5
colorama==0.4.4
cycler==0.10.0
decorator==4.4.2
gast @ file:///home/conda/feedstock_root/build_artifacts/gast_1596839682936/work
graphviz==0.16
grpcio @ file:///D:/bld/grpcio_1612023730616/work
h5py==2.7.1
imageio @ file:///home/conda/feedstock_root/build_artifacts/imageio_1594044661732/work
importlib-metadata @ file:///D:/bld/importlib-metadata_1610355323632/work
ipython==7.16.1
ipython-genutils==0.2.0
jedi==0.18.0
joblib==1.0.1
Keras==2.2.4
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.2
kiwisolver==1.3.1
Markdown @ file:///home/conda/feedstock_root/build_artifacts/markdown_1603668500820/work
matplotlib==3.3.4
natsort==7.1.1
numpy==1.16.4
olefile @ file:///home/conda/feedstock_root/build_artifacts/olefile_1602866521163/work
opencv-python==4.5.1.48
pandas==1.1.5
parso==0.8.1
pickleshare==0.7.5
Pillow @ file:///D:/bld/pillow_1610407611014/work
prompt-toolkit==3.0.16
protobuf==3.14.0
pydot==1.4.2
Pygments==2.8.1
pyparsing==2.4.7
pyreadline @ file:///D:/bld/pyreadline_1611175347303/work
python-dateutil==2.8.1
pytz==2021.1
PyYAML==5.4.1
scikit-learn==0.24.1
scipy==1.0.0
six @ file:///home/conda/feedstock_root/build_artifacts/six_1590081179328/work
sklearn==0.0
tensorboard==1.12.0
tensorflow==1.12.0
tensorflow-gpu==1.12.0
termcolor==1.1.0
threadpoolctl==2.1.0
traitlets==4.3.3
typing-extensions @ file:///home/conda/feedstock_root/build_artifacts/typing_extensions_1602702424206/work
wcwidth==0.2.5
Werkzeug==1.0.1
wincertstore==0.2
zipp @ file:///home/conda/feedstock_root/build_artifacts/zipp_1603668650351/work


-----------------------------------------------------------------------------------
import numpy as np
import cv2
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers


CROPDIR = "/Share/data/crop"
CROPs = os.listdir(CROPDIR)
crop_octa = []

for og in CROPs:
    img = np.asarray(cv2.imread(os.path.join(CROPDIR,og),cv2.IMREAD_GRAYSCALE))
    img = img/img.max().astype(float)
    crop_octa.append(img)
crop_octa = np.asarray(crop_octa)
datas = crop_octa
datas = tf.reshape(datas,(65,256,256,1))
datas.numpy().shape

class Sampling(layers.Layer):
    """Uses (z_mean, z_log_var) to sample z, the vector encoding a digit."""

    def call(self, inputs):
        z_mean, z_log_var = inputs
        batch = tf.shape(z_mean)[0]
        dim = tf.shape(z_mean)[1]
        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon



latent_dim = 2

encoder_inputs = keras.Input(shape=(256, 256, 1))
x = layers.Conv2D(256, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(256, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(128, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(128, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(64, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(64, 3, activation="relu", strides=1, padding="same")(encoder_inputs)
x = layers.Conv2D(32, 3, activation="relu", strides=1, padding="same")(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)
z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
z = Sampling()([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()



latent_inputs = keras.Input(shape=(latent_dim,))
x = layers.Dense(256*256*65, activation="relu")(latent_inputs)
x = layers.Reshape((256, 256, 65))(x)
x = layers.Conv2DTranspose(64, 3, activation="relu", strides=1, padding="same")(x)
x = layers.Conv2DTranspose(32, 3, activation="relu", strides=1, padding="same")(x)
decoder_outputs = layers.Conv2DTranspose(1, 3, activation="sigmoid", padding="same")(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
decoder.summary()


class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super(VAE, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.total_loss_tracker = keras.metrics.Mean(name="total_loss")
        self.reconstruction_loss_tracker = keras.metrics.Mean(
            name="reconstruction_loss"
        )
        self.kl_loss_tracker = keras.metrics.Mean(name="kl_loss")

    @property
    def metrics(self):
        return [
            self.total_loss_tracker,
            self.reconstruction_loss_tracker,
            self.kl_loss_tracker,
        ]

    def train_step(self, data):
        with tf.GradientTape() as tape:
            data = tf.reshape(data,(-1,256,256,1))
            z_mean, z_log_var, z = self.encoder(data)
            reconstruction = self.decoder(z)
            reconstruction_loss = tf.reduce_mean(
                tf.reduce_sum(
                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)
                )
            )
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))
            total_loss = reconstruction_loss + kl_loss
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            "loss": self.total_loss_tracker.result(),
            "reconstruction_loss": self.reconstruction_loss_tracker.result(),
            "kl_loss": self.kl_loss_tracker.result(),
        }
















vae = VAE(encoder, decoder)
vae.compile(optimizer=keras.optimizers.Adam())
print(datas.shape)
vae.fit(datas, epochs=1000, batch_size=4)





import matplotlib.pyplot as plt
plt.style.use('dark_background')

def plot_latent_space(vae, n=30, figsize=15):
    # display a n*n 2D manifold of digits
    digit_size = 256
    scale = 1.0
    figure = np.zeros((digit_size * n, digit_size * n))
    # linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]
    
    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            x_decoded = vae.decoder.predict(z_sample)
            digit = x_decoded[0].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.imshow(figure, cmap="gray")
    plt.show()

plt.figure(figsize=(15, 15))
for idx in range(1,10):
    plt.subplot(3,3,idx), plt.imshow(np.reshape(datas[idx], (256,256)), cmap='gray'), plt.axis(False)
    plt.subplots_adjust(wspace=0, hspace=0)
plt.show()

plot_latent_space(vae, n=3)


--------------------------------------------------- segnet encoder
latent_dim = 2

encoder_inputs = keras.Input(shape=(256, 256, 1))
x = layers.Conv2D(512, (3,3), strides=1, padding="same")(encoder_inputs)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2D(512, (3,3), strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.Conv2D(256, (3,3), strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(256, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.Conv2D(128, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(128, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.Conv2D(64, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(64, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.Conv2D(32, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(32, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)

x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)
z_mean = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
z = Sampling()([z_mean, z_log_var])
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
encoder.summary()


------------------segnet--------------------
latent_dim = 2

pool_size = (2,2)
encoder_inputs = keras.Input(shape=(256, 256, 1))
x = layers.Conv2D(16, (3,3), strides=1, padding="same")(encoder_inputs)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2D(16, (3,3), strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# x = layers.Dropout(0.5)(x)
x = layers.MaxPool2D(pool_size)(x)
c1 = x

x = layers.Conv2D(32, (3,3), strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(32, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# x = layers.Dropout(0.5)(x)
x = layers.MaxPool2D(pool_size)(x)
# c2 = preprocess_images(x)
c2 = x

x = layers.Conv2D(64, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(64, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# x = layers.Dropout(0.5)(x)
x = layers.MaxPool2D(pool_size)(x)
c3 = x

x = layers.Conv2D(128, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(128, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# x = layers.Dropout(0.5)(x)
x = layers.MaxPool2D(pool_size)(x)
c4 = x

x = layers.Conv2D(256, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
x = layers.Conv2D(256, (3,3), activation="relu", strides=1, padding="same")(x)
x = layers.BatchNormalization()(x)
x = layers.Activation("relu")(x)
# x = layers.Dropout(0.5)(x)
x = layers.MaxPool2D(pool_size)(x)

x = layers.Flatten()(x)
x = layers.Dense(16, activation="relu")(x)
z_mean    = layers.Dense(latent_dim, name="z_mean")(x)
z_log_var = layers.Dense(latent_dim, name="z_log_var")(x)
z = Sampling()([z_mean, z_log_var])

# encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name="encoder")
# encoder.summary()

# ----------- this is for decoder. -----------
# latent_inputs = keras.Input(shape=(latent_dim,))
# x = layers.Dense(8*8*32, activation="relu")(latent_inputs)
# x = layers.Reshape((8, 8, 32))(x)

# x = layers.UpSampling2D(interpolation='bilinear')(x)
# --------------------------------------------
x = layers.Dense(8*8*32, activation="relu")(z)
x = layers.Reshape((8, 8, 32))(x)
x = layers.UpSampling2D(interpolation='bilinear')(x)
x = layers.Conv2DTranspose(256, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(256, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
# x = layers.Dropout(0.5)(x)

x = layers.Concatenate(axis=-1)([x, c4])
x = layers.UpSampling2D(interpolation='bilinear')(x)
x = layers.Conv2DTranspose(128, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(128, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
# x = layers.Dropout(0.5)(x)

x = layers.Concatenate(axis=-1)([x, c3])
x = layers.UpSampling2D(interpolation='bilinear')(x)
x = layers.Conv2DTranspose(64, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(64, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
# x = layers.Dropout(0.5)(x)

x = layers.Concatenate(axis=-1)([x, c2])
x = layers.UpSampling2D(interpolation='bilinear')(x)
x = layers.Conv2DTranspose(32, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(32, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.5)(x)

x = layers.Concatenate(axis=-1)([x, c1])
x = layers.UpSampling2D(interpolation='bilinear')(x)
x = layers.Conv2DTranspose(16, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)
x = layers.Conv2DTranspose(16, (3,3), strides=1, padding="same")(x)
x = layers.Activation("relu")(x)
x = layers.BatchNormalization()(x)

decoder_outputs = layers.Conv2DTranspose(1, 3, activation="sigmoid", padding="same")(x)
# decoder = keras.Model(latent_inputs, decoder_outputs, name="decoder")
# decoder.summary()

SegNet = keras.Model(encoder_inputs, decoder_outputs, name="SegNet")
SegNet.summary()




----------------------------------------------------------------------
call back
----------------------------------------------------------------------
import shutil
shutil.rmtree('./checkpoint')
shutil.rmtree('./logs')
os.mkdir('./checkpoint')
os.mkdir('./logs')

vae_callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=20, monitor='reconstruction_loss' ), 
    tf.keras.callbacks.ModelCheckpoint(
        filepath=os.path.join('./checkpoint','model.{epoch:02d}-{loss:.2f}.h5'),
        # save_best_only=True --> validation 이 있어야 동작. 없어서 skipping 한다고 뜸
        ),
    tf.keras.callbacks.TensorBoard(log_dir = './logs')
]

seg_callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=10, monitor='loss' ), 
    tf.keras.callbacks.ModelCheckpoint(
        filepath=os.path.join('./checkpoint','model.{epoch:02d}-{loss:.2f}.h5'),
        save_best_only=True 
        ),
    tf.keras.callbacks.TensorBoard(log_dir = './logs')
]

----------------------------------------------------------------------

------------------------------Segnet fit------------------------------
SegNet.fit(
            train, train,
            epochs=1000, batch_size= 4,
            callbacks=seg_callbacks,
            validation_data = [valid, valid]
            )

----------------------------------------------------------------------



------------------------------Plot------------------------------
import matplotlib.pyplot as plt
plt.style.use('dark_background')

def plot_latent_space(vae, n=30, figsize=15):
    # display a n*n 2D manifold of digits
    digit_size = 256
    scale = 1.0
    figure = np.zeros((digit_size * n, digit_size * n))
    # linearly spaced coordinates corresponding to the 2D plot
    # of digit classes in the latent space
    grid_x = np.linspace(-scale, scale, n)
    grid_y = np.linspace(-scale, scale, n)[::-1]
    
    for i, yi in enumerate(grid_y):
        for j, xi in enumerate(grid_x):
            z_sample = np.array([[xi, yi]])
            print(z_sample)
            # vae.encoder()# test image 넣어서 z, z_mean, z_log_var 획득해서 => predict에 넘겨줘. plot은 test og image도 보여주고.
            x_decoded = vae.decoder.predict(z_sample)
            digit = x_decoded[0].reshape(digit_size, digit_size)
            figure[
                i * digit_size : (i + 1) * digit_size,
                j * digit_size : (j + 1) * digit_size,
            ] = digit

    plt.figure(figsize=(figsize, figsize))
    start_range = digit_size // 2
    end_range = n * digit_size + start_range
    pixel_range = np.arange(start_range, end_range, digit_size)
    sample_range_x = np.round(grid_x, 1)
    sample_range_y = np.round(grid_y, 1)
    plt.xticks(pixel_range, sample_range_x)
    plt.yticks(pixel_range, sample_range_y)
    plt.xlabel("z[0]")
    plt.ylabel("z[1]")
    plt.imshow(figure, cmap="gray")
    plt.show()


plt.figure(figsize=(20,100))
for idx in range(1,7,2):
    plt.subplot(7,2,idx), plt.imshow(np.reshape(test[idx], (256,256)), cmap="gray"), plt.axis(False), plt.title('input image')
    plt.subplots_adjust(wspace=0, hspace=0)
    
    # predict for VAE
    # z_mean, z_log_var, z = vae.encoder(tf.reshape(datas[idx],(1,256,256,1)))
    # x_decoded = vae.decoder.predict(z)
    # digit = x_decoded[0].reshape(256, 256)

    #predict for SegNet
    segnet_outs = SegNet.predict(tf.reshape(test[idx],(1,256,256,1)))
    digit = segnet_outs.reshape(256, 256)
    
    plt.subplot(7,2,idx+1), plt.imshow(digit, cmap="gray"), plt.axis(False), plt.title('output image')
    plt.subplots_adjust(wspace=0, hspace=0.1)

plt.show()




# plt.figure(figsize=(20,100))
# for idx in range(1,30,3):
#     plt.subplot(10,3,idx), plt.imshow(np.reshape(datas[idx], (256,256)), cmap='binary'), plt.axis(False), plt.title('input image')
#     plt.subplots_adjust(wspace=0, hspace=0)
    
#     z_mean, z_log_var, z = vae.encoder(tf.reshape(datas[idx],(1,256,256,1)))
#     x_decoded = vae.decoder.predict(z)
#     digit = x_decoded[0].reshape(256, 256)

#     plt.subplot(10,3,idx+1), plt.hist(z), plt.axis(True), plt.title('latent_space hist')
#     plt.subplots_adjust(wspace=0, hspace=0)

#     plt.subplot(10,3,idx+2), plt.imshow(digit, cmap="binary"), plt.axis(False), plt.title('output image')
#     plt.subplots_adjust(wspace=0, hspace=0)
# plt.show()


----------------------------------------------------------------------

























